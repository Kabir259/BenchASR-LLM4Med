{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":302713,"sourceType":"datasetVersion","datasetId":125828}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q evaluate datasets transformers jiwer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:44:47.549284Z","iopub.execute_input":"2024-11-24T04:44:47.551088Z","iopub.status.idle":"2024-11-24T04:44:58.681922Z","shell.execute_reply.started":"2024-11-24T04:44:47.551043Z","shell.execute_reply":"2024-11-24T04:44:58.680762Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torchaudio\nfrom datasets import Dataset, DatasetDict\nfrom transformers import (\n    Wav2Vec2Processor,\n    Wav2Vec2ForCTC,\n    Trainer,\n    TrainingArguments,\n    Wav2Vec2CTCTokenizer,\n    Wav2Vec2FeatureExtractor,\n)\nimport evaluate\nimport os\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional, Union\nimport numpy as np \n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:44:58.683997Z","iopub.execute_input":"2024-11-24T04:44:58.684766Z","iopub.status.idle":"2024-11-24T04:45:17.521697Z","shell.execute_reply.started":"2024-11-24T04:44:58.684722Z","shell.execute_reply":"2024-11-24T04:45:17.520813Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(new_session=False,\n      write_permission=True, \n      token='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', \n      add_to_git_credential=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:45:17.522677Z","iopub.execute_input":"2024-11-24T04:45:17.523223Z","iopub.status.idle":"2024-11-24T04:45:17.701463Z","shell.execute_reply.started":"2024-11-24T04:45:17.523192Z","shell.execute_reply":"2024-11-24T04:45:17.700656Z"}},"outputs":[{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"base_path = \"/kaggle/input/medical-speech-transcription-and-intent/Medical Speech, Transcription, and Intent\"\ncsv_file_path = os.path.join(base_path, \"overview-of-recordings.csv\")\nrecordings_path = os.path.join(base_path, \"recordings\")\n\ndf = pd.read_csv(csv_file_path)\n\ndef find_subdirectory_and_path(file_name):\n    for subdirectory in ['test', 'train', 'validate']:\n        file_path = os.path.join(recordings_path, subdirectory, file_name)\n        if os.path.exists(file_path):\n            return subdirectory, file_path\n    return None, None \n\ndf[['subdirectory', 'file_path']] = df['file_name'].apply(\n    lambda file_name: pd.Series(find_subdirectory_and_path(file_name))\n)\ndf = df.drop(['writer_id','speaker_id','file_download','file_name'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:45:17.703366Z","iopub.execute_input":"2024-11-24T04:45:17.703686Z","iopub.status.idle":"2024-11-24T04:45:34.570081Z","shell.execute_reply.started":"2024-11-24T04:45:17.703641Z","shell.execute_reply":"2024-11-24T04:45:34.569280Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict, Audio\nimport pandas as pd\n\ndataset = Dataset.from_pandas(df)\n\ntrain_dataset = dataset.filter(lambda x: x['subdirectory'] == 'train')\ntest_dataset = dataset.filter(lambda x: x['subdirectory'] == 'test')\nvalidate_dataset = dataset.filter(lambda x: x['subdirectory'] == 'validate')\n\ndataset_dict = DatasetDict({\n    \"train\": train_dataset,\n    \"test\": test_dataset,\n    \"validate\": validate_dataset\n})\n\nfor split in dataset_dict:\n    dataset_dict[split] = dataset_dict[split].cast_column(\"file_path\", Audio())\n    dataset_dict[split] = dataset_dict[split].rename_column(\"file_path\", \"audio\")\n    dataset_dict[split] = dataset_dict[split].rename_column(\"phrase\", \"text\")\n\n\ndata = dataset_dict.remove_columns([\"subdirectory\",\"prompt\",'audio_clipping', 'audio_clipping:confidence',\n                                    'background_noise_audible', 'background_noise_audible:confidence',\n                                    'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence'])\n\nprint(dataset_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:45:34.571188Z","iopub.execute_input":"2024-11-24T04:45:34.571456Z","iopub.status.idle":"2024-11-24T04:45:34.897337Z","shell.execute_reply.started":"2024-11-24T04:45:34.571430Z","shell.execute_reply":"2024-11-24T04:45:34.896490Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80643e473df24241b3e987459b39652e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42da2cc555b342eab09f043f9700922a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0edab7d2cfff43258dff8c06383208ea"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['audio_clipping', 'audio_clipping:confidence', 'background_noise_audible', 'background_noise_audible:confidence', 'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence', 'text', 'prompt', 'subdirectory', 'audio'],\n        num_rows: 381\n    })\n    test: Dataset({\n        features: ['audio_clipping', 'audio_clipping:confidence', 'background_noise_audible', 'background_noise_audible:confidence', 'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence', 'text', 'prompt', 'subdirectory', 'audio'],\n        num_rows: 5895\n    })\n    validate: Dataset({\n        features: ['audio_clipping', 'audio_clipping:confidence', 'background_noise_audible', 'background_noise_audible:confidence', 'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence', 'text', 'prompt', 'subdirectory', 'audio'],\n        num_rows: 385\n    })\n})\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import re\nchars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\ï\\`\\√\\d\\\\n]'\n\ndef remove_special_characters(batch):\n    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n    return batch\n    \ndata = data.map(remove_special_characters)\n\ndef extract_all_chars(batch):\n  all_text = \" \".join(batch[\"text\"])\n  vocab = list(set(all_text))\n  return {\"vocab\": [vocab], \"all_text\": [all_text]}\n\nvocabs = data.map(extract_all_chars, batched=True, \n                  batch_size=-1, \n                  keep_in_memory=True, \n                  remove_columns=data.column_names[\"train\"])\n\nvocab_list = list(set(vocabs[\"train\"][\"vocab\"][0]) | set(vocabs[\"test\"][\"vocab\"][0]))\nvocab_dict = {v: k for k, v in enumerate(sorted(vocab_list))}\n\nvocab_dict[\"|\"] = vocab_dict[\" \"]\ndel vocab_dict[\" \"]\nvocab_dict[\"[UNK]\"] = len(vocab_dict)\nvocab_dict[\"[PAD]\"] = len(vocab_dict)\n\nimport json\n\nwith open('vocab.json', 'w') as vocab_file:\n    json.dump(vocab_dict, vocab_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:45:34.898481Z","iopub.execute_input":"2024-11-24T04:45:34.899171Z","iopub.status.idle":"2024-11-24T04:45:35.530170Z","shell.execute_reply.started":"2024-11-24T04:45:34.899130Z","shell.execute_reply":"2024-11-24T04:45:35.529373Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/381 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72c9311a658e422f92ab8df6889731e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb15e3049ef49689f25a2fa5b7d9b0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/385 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d98f679ba73f48948b4839fd1d2b3bb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/381 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61a73846488b46cfa5ef60b5cbe7ee2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa91ded49e914c3288abd80d1c096cb8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/385 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11962f2f3efe42469d8b7b669dfe4c85"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from transformers import Wav2Vec2CTCTokenizer\n\ntokenizer = Wav2Vec2CTCTokenizer( # added from_pretrained\n    \"./vocab.json\",\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    word_delimiter_token=\"|\"\n    # return_tensors=\"pt\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:46:52.464939Z","iopub.execute_input":"2024-11-24T04:46:52.465813Z","iopub.status.idle":"2024-11-24T04:46:52.470382Z","shell.execute_reply.started":"2024-11-24T04:46:52.465775Z","shell.execute_reply":"2024-11-24T04:46:52.469507Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from transformers import SeamlessM4TFeatureExtractor\n\nfeature_extractor = SeamlessM4TFeatureExtractor(feature_size=80, num_mel_bins=80, sampling_rate=16000, padding_value=0.0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:46:53.228001Z","iopub.execute_input":"2024-11-24T04:46:53.228683Z","iopub.status.idle":"2024-11-24T04:46:53.233682Z","shell.execute_reply.started":"2024-11-24T04:46:53.228649Z","shell.execute_reply":"2024-11-24T04:46:53.232840Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from transformers import Wav2Vec2BertProcessor\n\nprocessor = Wav2Vec2BertProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:46:53.909258Z","iopub.execute_input":"2024-11-24T04:46:53.909937Z","iopub.status.idle":"2024-11-24T04:46:53.913808Z","shell.execute_reply.started":"2024-11-24T04:46:53.909904Z","shell.execute_reply":"2024-11-24T04:46:53.912931Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import Wav2Vec2BertForCTC, TrainingArguments, Trainer\n\nmodel = Wav2Vec2BertForCTC.from_pretrained(\n    \"facebook/w2v-bert-2.0\",\n    # attention_dropout=0.0,\n    # hidden_dropout=0.0,\n    # feat_proj_dropout=0.0,\n    # mask_time_prob=0.0,\n    # layerdrop=0.0,\n    # ctc_loss_reduction=\"mean\",\n    add_adapter=True,\n    pad_token_id=processor.tokenizer.pad_token_id,\n    vocab_size=len(processor.tokenizer),\n).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:54:27.009850Z","iopub.execute_input":"2024-11-24T04:54:27.010827Z","iopub.status.idle":"2024-11-24T04:54:28.594094Z","shell.execute_reply.started":"2024-11-24T04:54:27.010778Z","shell.execute_reply":"2024-11-24T04:54:28.593144Z"}},"outputs":[{"name":"stderr","text":"Some weights of Wav2Vec2BertForCTC were not initialized from the model checkpoint at facebook/w2v-bert-2.0 and are newly initialized: ['adapter.layers.0.ffn.intermediate_dense.bias', 'adapter.layers.0.ffn.intermediate_dense.weight', 'adapter.layers.0.ffn.output_dense.bias', 'adapter.layers.0.ffn.output_dense.weight', 'adapter.layers.0.ffn_layer_norm.bias', 'adapter.layers.0.ffn_layer_norm.weight', 'adapter.layers.0.residual_conv.bias', 'adapter.layers.0.residual_conv.weight', 'adapter.layers.0.residual_layer_norm.bias', 'adapter.layers.0.residual_layer_norm.weight', 'adapter.layers.0.self_attn.linear_k.bias', 'adapter.layers.0.self_attn.linear_k.weight', 'adapter.layers.0.self_attn.linear_out.bias', 'adapter.layers.0.self_attn.linear_out.weight', 'adapter.layers.0.self_attn.linear_q.bias', 'adapter.layers.0.self_attn.linear_q.weight', 'adapter.layers.0.self_attn.linear_v.bias', 'adapter.layers.0.self_attn.linear_v.weight', 'adapter.layers.0.self_attn_conv.bias', 'adapter.layers.0.self_attn_conv.weight', 'adapter.layers.0.self_attn_layer_norm.bias', 'adapter.layers.0.self_attn_layer_norm.weight', 'lm_head.bias', 'lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"def prepare_dataset(batch):\n    audio = batch[\"audio\"]\n    batch[\"input_features\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n    batch[\"input_length\"] = len(batch[\"input_features\"])\n\n    batch[\"labels\"] = processor(text=batch[\"text\"]).input_ids\n    return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:48:40.752838Z","iopub.execute_input":"2024-11-24T04:48:40.753068Z","iopub.status.idle":"2024-11-24T04:48:40.757730Z","shell.execute_reply.started":"2024-11-24T04:48:40.753043Z","shell.execute_reply":"2024-11-24T04:48:40.756902Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"data = data.cast_column(\"audio\", Audio(sampling_rate=16_000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:48:40.759140Z","iopub.execute_input":"2024-11-24T04:48:40.759374Z","iopub.status.idle":"2024-11-24T04:48:40.774765Z","shell.execute_reply.started":"2024-11-24T04:48:40.759349Z","shell.execute_reply":"2024-11-24T04:48:40.774070Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"data = data.map(prepare_dataset, remove_columns=data.column_names[\"validate\"], num_proc=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:48:40.775759Z","iopub.execute_input":"2024-11-24T04:48:40.776312Z","iopub.status.idle":"2024-11-24T04:53:39.215967Z","shell.execute_reply.started":"2024-11-24T04:48:40.776275Z","shell.execute_reply":"2024-11-24T04:53:39.215059Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/381 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06415b2f00004451b92beaa905856c38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/5895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08c1ec8a36694f1983c007337e18dd67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/385 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96a1bb422835460a8738c3865174fa9f"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"def map_to_result(batch):\n    with torch.no_grad():\n        # Extract features and pass them through the model\n        input_features = torch.tensor(batch[\"input_features\"], device=\"cuda\").unsqueeze(0)\n        logits = model(input_features).logits\n\n        # Get predicted token IDs\n        pred_ids = torch.argmax(logits, dim=-1)\n\n        # Decode predictions\n        batch[\"pred_str\"] = processor.batch_decode(pred_ids, skip_special_tokens=True)[0].strip()  # Combine tokens\n        batch[\"text\"] = processor.decode(batch[\"labels\"], group_tokens=False).strip()  # Clean up references\n\n    return batch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:53:39.217891Z","iopub.execute_input":"2024-11-24T04:53:39.218180Z","iopub.status.idle":"2024-11-24T04:53:39.224084Z","shell.execute_reply.started":"2024-11-24T04:53:39.218150Z","shell.execute_reply":"2024-11-24T04:53:39.223085Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"results = data[\"validate\"].map(map_to_result, remove_columns=data[\"validate\"].column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:54:36.202148Z","iopub.execute_input":"2024-11-24T04:54:36.202498Z","iopub.status.idle":"2024-11-24T04:55:27.387955Z","shell.execute_reply.started":"2024-11-24T04:54:36.202466Z","shell.execute_reply":"2024-11-24T04:55:27.386939Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/385 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dc032e3f4e147e4abf10baca17b7f88"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"predictions = [pred.strip() for pred in results[\"pred_str\"]]  # Remove extra spaces and special tokens\nreferences = [ref.strip() for ref in results[\"text\"]]  # Remove extra spaces","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:56:17.128034Z","iopub.execute_input":"2024-11-24T04:56:17.128425Z","iopub.status.idle":"2024-11-24T04:56:17.134635Z","shell.execute_reply.started":"2024-11-24T04:56:17.128392Z","shell.execute_reply":"2024-11-24T04:56:17.133668Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nwer_metric = evaluate.load(\"wer\")\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = float('inf') # init wer with a default value\n\n    try:\n        wer = wer_metric.compute(predictions=pred_str, references=label_str)\n    except Exception as e:\n        print(f\"Error computing WER. Predictions: {pred_str}, References: {label_str}, Error: {e}\")\n\n    return {\"wer\": wer}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:56:18.057674Z","iopub.execute_input":"2024-11-24T04:56:18.058055Z","iopub.status.idle":"2024-11-24T04:56:18.686537Z","shell.execute_reply.started":"2024-11-24T04:56:18.058023Z","shell.execute_reply":"2024-11-24T04:56:18.685667Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"809c76145e624eba8b69881744e495ef"}},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"wer = wer_metric.compute(predictions=predictions, references=references)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:56:20.375486Z","iopub.execute_input":"2024-11-24T04:56:20.376113Z","iopub.status.idle":"2024-11-24T04:56:20.409198Z","shell.execute_reply.started":"2024-11-24T04:56:20.376077Z","shell.execute_reply":"2024-11-24T04:56:20.408360Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"print(\"w2v2-base_kabir Val WER: {:.3f}\".format(wer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:56:21.915116Z","iopub.execute_input":"2024-11-24T04:56:21.915798Z","iopub.status.idle":"2024-11-24T04:56:21.920164Z","shell.execute_reply.started":"2024-11-24T04:56:21.915762Z","shell.execute_reply":"2024-11-24T04:56:21.919241Z"}},"outputs":[{"name":"stdout","text":"w2v2-base_kabir Val WER: 1.000\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from datasets import ClassLabel\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    display(HTML(df.to_html()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:56:24.223522Z","iopub.execute_input":"2024-11-24T04:56:24.224103Z","iopub.status.idle":"2024-11-24T04:56:24.229961Z","shell.execute_reply.started":"2024-11-24T04:56:24.224048Z","shell.execute_reply":"2024-11-24T04:56:24.228912Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"show_random_elements(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T04:56:26.171815Z","iopub.execute_input":"2024-11-24T04:56:26.172171Z","iopub.status.idle":"2024-11-24T04:56:26.183156Z","shell.execute_reply.started":"2024-11-24T04:56:26.172138Z","shell.execute_reply":"2024-11-24T04:56:26.182314Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pred_str</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>d gcdehdodwdcycucdbdcbdknpvncnhdvucudgdgdwbcdqbabpbaldbabgc</td>\n      <td>i feel discomfort throughout the body in general</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cdcdcdcdabuvavbdljewbcdcdvbcecvndcdrcwdcvcbcndcbdgcdwimcdubnb</td>\n      <td>the warming system of my house is broken and  feel so cold</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cdkcdvdwcavbjdjdcdcbcacgzyqedadgzrzwb</td>\n      <td>i was travelling by ship and i feel dizzy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cdckcbdbdgwdgrjowadcudbdvibv gcdegnvacdbdw</td>\n      <td>i feel pain in my heart when i wake up</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cdcdbcgudungdhidwdwdcngwygapb</td>\n      <td>i have blurred vision</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cnhrdnbulgqnvibilwdweucbwednbnipdpdcixlxyecejucbgnvabgcabzwapvbnhvdrpuycg</td>\n      <td>i feel like i went to an acupuncture's practice and had  needles in my shoulder</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dcnbcdcdcdvbicdcdvuavugdwpcdcdbcdw</td>\n      <td>i feel weak all over</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>dgndcecdc cnjxcgdjpivdwcvdbdqypzcugubvjblbjvavagdg</td>\n      <td>i have eruptions on my face that come and go</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>cdcwcdwdcdunbdnbpgvcpdcudujdjbdbvlucdubdcdcdc</td>\n      <td>i feel aching on my insides</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cbnwbnbucbyzpcbcnda cegwgzypdwgadymibicdcdvcbdpdwbdcdcwygwidbdbgnpvjucvykndcbyducawcndcncn</td>\n      <td>i have a foot ache in winter or when it feels cold why</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}