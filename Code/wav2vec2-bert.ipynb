{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics Installs & Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:01.132350Z",
     "iopub.status.busy": "2024-11-24T00:56:01.131757Z",
     "iopub.status.idle": "2024-11-24T00:56:11.660456Z",
     "shell.execute_reply": "2024-11-24T00:56:11.659520Z",
     "shell.execute_reply.started": "2024-11-24T00:56:01.132310Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! pip install --quiet transformers datasets evaluate jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:20.099162Z",
     "iopub.status.busy": "2024-11-24T00:56:20.098891Z",
     "iopub.status.idle": "2024-11-24T00:56:39.145931Z",
     "shell.execute_reply": "2024-11-24T00:56:39.145058Z",
     "shell.execute_reply.started": "2024-11-24T00:56:20.099136Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForCTC,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    ")\n",
    "import evaluate\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Union\n",
    "import numpy as np \n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:39.148092Z",
     "iopub.status.busy": "2024-11-24T00:56:39.147545Z",
     "iopub.status.idle": "2024-11-24T00:56:39.283969Z",
     "shell.execute_reply": "2024-11-24T00:56:39.283129Z",
     "shell.execute_reply.started": "2024-11-24T00:56:39.148063Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(new_session=False,\n",
    "      write_permission=True, \n",
    "      token='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', \n",
    "      add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:39.285227Z",
     "iopub.status.busy": "2024-11-24T00:56:39.284976Z",
     "iopub.status.idle": "2024-11-24T00:56:55.482225Z",
     "shell.execute_reply": "2024-11-24T00:56:55.481218Z",
     "shell.execute_reply.started": "2024-11-24T00:56:39.285202Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = \"/kaggle/input/medical-speech-transcription-and-intent/Medical Speech, Transcription, and Intent\"\n",
    "csv_file_path = os.path.join(base_path, \"overview-of-recordings.csv\")\n",
    "recordings_path = os.path.join(base_path, \"recordings\")\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "def find_subdirectory_and_path(file_name):\n",
    "    for subdirectory in ['test', 'train', 'validate']:\n",
    "        file_path = os.path.join(recordings_path, subdirectory, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            return subdirectory, file_path\n",
    "    return None, None \n",
    "\n",
    "df[['subdirectory', 'file_path']] = df['file_name'].apply(\n",
    "    lambda file_name: pd.Series(find_subdirectory_and_path(file_name))\n",
    ")\n",
    "df = df.drop(['writer_id','speaker_id','file_download','file_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:55.483953Z",
     "iopub.status.busy": "2024-11-24T00:56:55.483554Z",
     "iopub.status.idle": "2024-11-24T00:56:55.810659Z",
     "shell.execute_reply": "2024-11-24T00:56:55.809803Z",
     "shell.execute_reply.started": "2024-11-24T00:56:55.483898Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f55c58977464ef4afe9599dd1828e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f5ee005be34979b0f53f26ec3cf14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba9cbd27f854ffda34ed8c43d008954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio_clipping', 'audio_clipping:confidence', 'background_noise_audible', 'background_noise_audible:confidence', 'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence', 'text', 'prompt', 'subdirectory', 'audio'],\n",
      "        num_rows: 381\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio_clipping', 'audio_clipping:confidence', 'background_noise_audible', 'background_noise_audible:confidence', 'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence', 'text', 'prompt', 'subdirectory', 'audio'],\n",
      "        num_rows: 5895\n",
      "    })\n",
      "    validate: Dataset({\n",
      "        features: ['audio_clipping', 'audio_clipping:confidence', 'background_noise_audible', 'background_noise_audible:confidence', 'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence', 'text', 'prompt', 'subdirectory', 'audio'],\n",
      "        num_rows: 385\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, Audio\n",
    "import pandas as pd\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "train_dataset = dataset.filter(lambda x: x['subdirectory'] == 'train')\n",
    "test_dataset = dataset.filter(lambda x: x['subdirectory'] == 'test')\n",
    "validate_dataset = dataset.filter(lambda x: x['subdirectory'] == 'validate')\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validate\": validate_dataset\n",
    "})\n",
    "\n",
    "for split in dataset_dict:\n",
    "    dataset_dict[split] = dataset_dict[split].cast_column(\"file_path\", Audio())\n",
    "    dataset_dict[split] = dataset_dict[split].rename_column(\"file_path\", \"audio\")\n",
    "    dataset_dict[split] = dataset_dict[split].rename_column(\"phrase\", \"text\")\n",
    "\n",
    "\n",
    "data = dataset_dict.remove_columns([\"subdirectory\",\"prompt\",'audio_clipping', 'audio_clipping:confidence',\n",
    "                                    'background_noise_audible', 'background_noise_audible:confidence',\n",
    "                                    'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence'])\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:55.812168Z",
     "iopub.status.busy": "2024-11-24T00:56:55.811831Z",
     "iopub.status.idle": "2024-11-24T00:56:56.487040Z",
     "shell.execute_reply": "2024-11-24T00:56:56.486240Z",
     "shell.execute_reply.started": "2024-11-24T00:56:55.812132Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ce32965cef4951b4f20eedab33a80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dab410b7dbb4a75b7c5ddf661bb4508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e4544ba76f4aba8e6eca0f81b289f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d63550baf247d58a0e695ed6a1c3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3b4f4f594844b58ddfec0d0bade43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286e30b556084b6092718980f52219ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\ï\\`\\√\\d\\\\n]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n",
    "    return batch\n",
    "    \n",
    "data = data.map(remove_special_characters)\n",
    "\n",
    "def extract_all_chars(batch):\n",
    "  all_text = \" \".join(batch[\"text\"])\n",
    "  vocab = list(set(all_text))\n",
    "  return {\"vocab\": [vocab], \"all_text\": [all_text]}\n",
    "\n",
    "vocabs = data.map(extract_all_chars, batched=True, \n",
    "                  batch_size=-1, \n",
    "                  keep_in_memory=True, \n",
    "                  remove_columns=data.column_names[\"train\"])\n",
    "\n",
    "vocab_list = list(set(vocabs[\"train\"][\"vocab\"][0]) | set(vocabs[\"test\"][\"vocab\"][0]))\n",
    "vocab_dict = {v: k for k, v in enumerate(sorted(vocab_list))}\n",
    "\n",
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n",
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "\n",
    "import json\n",
    "\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:56.488818Z",
     "iopub.status.busy": "2024-11-24T00:56:56.488239Z",
     "iopub.status.idle": "2024-11-24T00:56:56.495234Z",
     "shell.execute_reply": "2024-11-24T00:56:56.494456Z",
     "shell.execute_reply.started": "2024-11-24T00:56:56.488777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_dict) # should be below 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:56.496489Z",
     "iopub.status.busy": "2024-11-24T00:56:56.496216Z",
     "iopub.status.idle": "2024-11-24T00:56:56.516298Z",
     "shell.execute_reply": "2024-11-24T00:56:56.515422Z",
     "shell.execute_reply.started": "2024-11-24T00:56:56.496465Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer( # added from_pretrained\n",
    "    \"./vocab.json\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    word_delimiter_token=\"|\"\n",
    "    # return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:56.519067Z",
     "iopub.status.busy": "2024-11-24T00:56:56.518825Z",
     "iopub.status.idle": "2024-11-24T00:56:56.528126Z",
     "shell.execute_reply": "2024-11-24T00:56:56.527448Z",
     "shell.execute_reply.started": "2024-11-24T00:56:56.519044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import SeamlessM4TFeatureExtractor\n",
    "\n",
    "feature_extractor = SeamlessM4TFeatureExtractor(feature_size=80, num_mel_bins=80, sampling_rate=16000, padding_value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:56.529373Z",
     "iopub.status.busy": "2024-11-24T00:56:56.529124Z",
     "iopub.status.idle": "2024-11-24T00:56:56.536103Z",
     "shell.execute_reply": "2024-11-24T00:56:56.535420Z",
     "shell.execute_reply.started": "2024-11-24T00:56:56.529349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2BertProcessor\n",
    "\n",
    "processor = Wav2Vec2BertProcessor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:56.537435Z",
     "iopub.status.busy": "2024-11-24T00:56:56.537092Z",
     "iopub.status.idle": "2024-11-24T00:56:56.547821Z",
     "shell.execute_reply": "2024-11-24T00:56:56.547026Z",
     "shell.execute_reply.started": "2024-11-24T00:56:56.537374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_features\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    batch[\"input_length\"] = len(batch[\"input_features\"])\n",
    "\n",
    "    batch[\"labels\"] = processor(text=batch[\"text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:56.548899Z",
     "iopub.status.busy": "2024-11-24T00:56:56.548660Z",
     "iopub.status.idle": "2024-11-24T00:56:56.562189Z",
     "shell.execute_reply": "2024-11-24T00:56:56.561310Z",
     "shell.execute_reply.started": "2024-11-24T00:56:56.548876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = data.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T00:56:56.563818Z",
     "iopub.status.busy": "2024-11-24T00:56:56.563228Z",
     "iopub.status.idle": "2024-11-24T01:02:01.015742Z",
     "shell.execute_reply": "2024-11-24T01:02:01.014833Z",
     "shell.execute_reply.started": "2024-11-24T00:56:56.563781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf7600b4f94488599000de5eb08aac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/381 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9abd92651eb745afb5439b2358266caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dae5d04add44e589da177f5fc09c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.map(prepare_dataset, remove_columns=data.column_names[\"train\"], num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T01:02:01.017564Z",
     "iopub.status.busy": "2024-11-24T01:02:01.017182Z",
     "iopub.status.idle": "2024-11-24T01:02:01.026795Z",
     "shell.execute_reply": "2024-11-24T01:02:01.025771Z",
     "shell.execute_reply.started": "2024-11-24T01:02:01.017532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2BertProcessor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        labels_batch = self.processor.pad(\n",
    "            labels=label_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T01:02:01.027897Z",
     "iopub.status.busy": "2024-11-24T01:02:01.027647Z",
     "iopub.status.idle": "2024-11-24T01:02:01.678174Z",
     "shell.execute_reply": "2024-11-24T01:02:01.677318Z",
     "shell.execute_reply.started": "2024-11-24T01:02:01.027872Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cae47dea664fc1bb06f05f84efe57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    # Replace -100 with the tokenizer's pad token ID\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # We do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    # Initialize wer with a default value\n",
    "    wer = float('inf')\n",
    "\n",
    "    try:\n",
    "        wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing WER. Predictions: {pred_str}, References: {label_str}, Error: {e}\")\n",
    "\n",
    "\n",
    "    return {\"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T01:02:01.679465Z",
     "iopub.status.busy": "2024-11-24T01:02:01.679182Z",
     "iopub.status.idle": "2024-11-24T01:02:01.683293Z",
     "shell.execute_reply": "2024-11-24T01:02:01.682322Z",
     "shell.execute_reply.started": "2024-11-24T01:02:01.679432Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wandb: 25d0c05384d1f94a41954af5bd655f4014f67ee5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T01:02:01.684650Z",
     "iopub.status.busy": "2024-11-24T01:02:01.684353Z",
     "iopub.status.idle": "2024-11-24T02:34:58.660743Z",
     "shell.execute_reply": "2024-11-24T02:34:58.659995Z",
     "shell.execute_reply.started": "2024-11-24T01:02:01.684624Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396ed46fd35c49f6bb97276c72332821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8d6f9e28fe43518cf4d42bea8d3c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2BertForCTC were not initialized from the model checkpoint at facebook/w2v-bert-2.0 and are newly initialized: ['adapter.layers.0.ffn.intermediate_dense.bias', 'adapter.layers.0.ffn.intermediate_dense.weight', 'adapter.layers.0.ffn.output_dense.bias', 'adapter.layers.0.ffn.output_dense.weight', 'adapter.layers.0.ffn_layer_norm.bias', 'adapter.layers.0.ffn_layer_norm.weight', 'adapter.layers.0.residual_conv.bias', 'adapter.layers.0.residual_conv.weight', 'adapter.layers.0.residual_layer_norm.bias', 'adapter.layers.0.residual_layer_norm.weight', 'adapter.layers.0.self_attn.linear_k.bias', 'adapter.layers.0.self_attn.linear_k.weight', 'adapter.layers.0.self_attn.linear_out.bias', 'adapter.layers.0.self_attn.linear_out.weight', 'adapter.layers.0.self_attn.linear_q.bias', 'adapter.layers.0.self_attn.linear_q.weight', 'adapter.layers.0.self_attn.linear_v.bias', 'adapter.layers.0.self_attn.linear_v.weight', 'adapter.layers.0.self_attn_conv.bias', 'adapter.layers.0.self_attn_conv.weight', 'adapter.layers.0.self_attn_layer_norm.bias', 'adapter.layers.0.self_attn_layer_norm.weight', 'lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d920bff854c244b5a0c3e5379adc5c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112909066666059, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241124_010337-zity0490</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kabirkumar-iit-delhi/huggingface/runs/zity0490' target=\"_blank\">w2v2-BERT_kabir</a></strong> to <a href='https://wandb.ai/kabirkumar-iit-delhi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kabirkumar-iit-delhi/huggingface' target=\"_blank\">https://wandb.ai/kabirkumar-iit-delhi/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kabirkumar-iit-delhi/huggingface/runs/zity0490' target=\"_blank\">https://wandb.ai/kabirkumar-iit-delhi/huggingface/runs/zity0490</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 1:30:04, Epoch 41/42]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.231017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.246229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.5291484557390213, metrics={'train_runtime': 5449.2867, 'train_samples_per_second': 2.936, 'train_steps_per_second': 0.184, 'total_flos': 2.476436924551772e+18, 'train_loss': 0.5291484557390213, 'epoch': 41.666666666666664})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2BertForCTC, TrainingArguments, Trainer\n",
    "\n",
    "model = Wav2Vec2BertForCTC.from_pretrained(\n",
    "    \"facebook/w2v-bert-2.0\",\n",
    "    attention_dropout=0.0,\n",
    "    hidden_dropout=0.0,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.0,\n",
    "    layerdrop=0.0,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    add_adapter=True,\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer),\n",
    ")\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"w2v2-BERT_kabir\",\n",
    "    per_device_train_batch_size=8,  \n",
    "    gradient_accumulation_steps=2,  \n",
    "    learning_rate=5e-5,  # experiment\n",
    "    weight_decay = 0.005, # experiment\n",
    "    lr_scheduler_type=\"cosine\",  # experiment\n",
    "    warmup_steps=200,  # experiemnt, ~10% of max_steps\n",
    "    max_steps=1000,  # experiment\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    group_by_length=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=25,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data[\"test\"],\n",
    "    tokenizer=processor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T02:34:58.662136Z",
     "iopub.status.busy": "2024-11-24T02:34:58.661865Z",
     "iopub.status.idle": "2024-11-24T02:35:12.992883Z",
     "shell.execute_reply": "2024-11-24T02:35:12.991991Z",
     "shell.execute_reply.started": "2024-11-24T02:34:58.662109Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Kabir259/w2v2-BERT_kabir/commit/06b9a310f7a6d2f757439c1dad178182fe6ea894', commit_message='End of training', commit_description='', oid='06b9a310f7a6d2f757439c1dad178182fe6ea894', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Kabir259/w2v2-BERT_kabir', endpoint='https://huggingface.co', repo_type='model', repo_id='Kabir259/w2v2-BERT_kabir'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('w2v2-BERT_kabir')\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T02:35:12.994334Z",
     "iopub.status.busy": "2024-11-24T02:35:12.994062Z",
     "iopub.status.idle": "2024-11-24T02:35:12.999734Z",
     "shell.execute_reply": "2024-11-24T02:35:12.998911Z",
     "shell.execute_reply.started": "2024-11-24T02:35:12.994307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !zip -r w2v2-base_1.0.zip /kaggle/working/w2v2-BERT_kabir"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 125828,
     "sourceId": 302713,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
