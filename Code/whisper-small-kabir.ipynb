{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":302713,"sourceType":"datasetVersion","datasetId":125828}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -q transformers datasets evaluate jiwer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:09:37.649079Z","iopub.execute_input":"2024-11-24T17:09:37.649618Z","iopub.status.idle":"2024-11-24T17:09:48.257920Z","shell.execute_reply.started":"2024-11-24T17:09:37.649584Z","shell.execute_reply":"2024-11-24T17:09:48.256966Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torchaudio\nfrom datasets import Dataset, DatasetDict\nfrom transformers import (\n    WhisperTokenizer,\n    WhisperProcessor,\n    WhisperFeatureExtractor,\n    WhisperForConditionalGeneration,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer\n)\nimport evaluate\nimport os\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional, Union\nimport numpy as np \n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:09:48.259661Z","iopub.execute_input":"2024-11-24T17:09:48.260012Z","iopub.status.idle":"2024-11-24T17:10:07.527213Z","shell.execute_reply.started":"2024-11-24T17:09:48.259981Z","shell.execute_reply":"2024-11-24T17:10:07.526260Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(new_session=False,\n      write_permission=True, \n      token='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', \n      add_to_git_credential=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:07.528231Z","iopub.execute_input":"2024-11-24T17:10:07.528771Z","iopub.status.idle":"2024-11-24T17:10:07.665763Z","shell.execute_reply.started":"2024-11-24T17:10:07.528743Z","shell.execute_reply":"2024-11-24T17:10:07.665010Z"}},"outputs":[{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport pandas as pd\nfrom datasets import Dataset, Audio\n\n# Define base paths\nbase_path = \"/kaggle/input/medical-speech-transcription-and-intent/Medical Speech, Transcription, and Intent\"\ncsv_file_path = os.path.join(base_path, \"overview-of-recordings.csv\")\nrecordings_path = os.path.join(base_path, \"recordings\")\n\n# Load CSV\ndf = pd.read_csv(csv_file_path)\n\n# Function to find the subdirectory and file path\ndef find_subdirectory_and_path(file_name):\n    for subdirectory in ['test', 'train', 'validate']:\n        file_path = os.path.join(recordings_path, subdirectory, file_name)\n        if os.path.exists(file_path):\n            return subdirectory, file_path\n    return None, None \n\n# Apply the function to find subdirectories and paths\ndf[['subdirectory', 'file_path']] = df['file_name'].apply(\n    lambda file_name: pd.Series(find_subdirectory_and_path(file_name))\n)\n\n# Drop unnecessary columns\ndf = df.drop(['writer_id', 'speaker_id', 'file_download', 'file_name'], axis=1)\n\n# Convert dataframe to dataset\ndataset = Dataset.from_pandas(df)\n\n# Split the dataset into train, test, and validate\ntrain_data = dataset.filter(lambda x: x['subdirectory'] == 'train')\ntest_data = dataset.filter(lambda x: x['subdirectory'] == 'test')\nval_data = dataset.filter(lambda x: x['subdirectory'] == 'validate')\n\n# Cast and rename columns for each split\nfor split_name, split_data in zip(['train', 'test', 'validate'], [train_data, test_data, val_data]):\n    split_data = split_data.cast_column(\"file_path\", Audio())\n    split_data = split_data.rename_column(\"file_path\", \"audio\")\n    split_data = split_data.rename_column(\"phrase\", \"text\")\n    if split_name == 'train':\n        train_data = split_data\n    elif split_name == 'test':\n        test_data = split_data\n    elif split_name == 'validate':\n        val_data = split_data\n\n# Remove unnecessary columns from each split\ncolumns_to_remove = [\n    \"subdirectory\", \"prompt\", 'audio_clipping', 'audio_clipping:confidence',\n    'background_noise_audible', 'background_noise_audible:confidence',\n    'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence'\n]\n\ntrain_data = train_data.remove_columns(columns_to_remove)\ntest_data = test_data.remove_columns(columns_to_remove)\nval_data = val_data.remove_columns(columns_to_remove)\n\n# Format preview for a single sample\ndef preview_sample(dataset):\n    sample = dataset[0]  # First sample in the dataset\n    return {\n        \"audio\": {\n            \"path\": sample[\"audio\"][\"path\"],\n            \"array\": sample[\"audio\"][\"array\"],  # No need to convert; it's already a list or numpy array\n            \"sampling_rate\": sample[\"audio\"][\"sampling_rate\"],\n        },\n        \"text\": sample[\"text\"]\n    }\n\nprint(\"Train Data:\", train_data)\ntrain_sample = preview_sample(train_data)\nprint(\"Train Sample:\", train_sample)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:07.667678Z","iopub.execute_input":"2024-11-24T17:10:07.667984Z","iopub.status.idle":"2024-11-24T17:10:38.727461Z","shell.execute_reply.started":"2024-11-24T17:10:07.667956Z","shell.execute_reply":"2024-11-24T17:10:38.726502Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67730c930b614c15aaa2c6b60a4f3a23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b0d91b9910f43ef9186579e9f264a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a7d1fa742ac4ea0be816fcabeb3d280"}},"metadata":{}},{"name":"stdout","text":"Train Data: Dataset({\n    features: ['text', 'audio'],\n    num_rows: 381\n})\nTrain Sample: {'audio': {'path': '/kaggle/input/medical-speech-transcription-and-intent/Medical Speech, Transcription, and Intent/recordings/train/1249120_44197979_23991689.wav', 'array': array([0.02072144, 0.01501465, 0.01168823, ..., 0.05114746, 0.10168457,\n       0.07489014]), 'sampling_rate': 48000}, 'text': 'I have a sharp pain in my lower stomach.'}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train_data = train_data.cast_column(\"audio\", Audio(sampling_rate=16000))\ntest_data = test_data.cast_column(\"audio\", Audio(sampling_rate=16000))\nval_data = val_data.cast_column(\"audio\", Audio(sampling_rate=16000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:38.728417Z","iopub.execute_input":"2024-11-24T17:10:38.729088Z","iopub.status.idle":"2024-11-24T17:10:38.739782Z","shell.execute_reply.started":"2024-11-24T17:10:38.729049Z","shell.execute_reply":"2024-11-24T17:10:38.738843Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import re\nchars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\Ã¯\\`\\âˆš\\d\\\\n]'\n\ndef remove_special_characters(batch):\n    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n    return batch\n    \ntrain_data = train_data.map(remove_special_characters)\ntest_data = test_data.map(remove_special_characters)\nval_data = val_data.map(remove_special_characters)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:38.740994Z","iopub.execute_input":"2024-11-24T17:10:38.741270Z","iopub.status.idle":"2024-11-24T17:10:39.365057Z","shell.execute_reply.started":"2024-11-24T17:10:38.741243Z","shell.execute_reply":"2024-11-24T17:10:39.364186Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/381 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cefe5d2a81df4c588fe26f6669cb0b10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"502f5fb394e14b57a5febe1a8fdf63a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/385 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"390b619c190843e6beed030609119008"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model_id = 'openai/whisper-small'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:39.366141Z","iopub.execute_input":"2024-11-24T17:10:39.366406Z","iopub.status.idle":"2024-11-24T17:10:39.370221Z","shell.execute_reply.started":"2024-11-24T17:10:39.366379Z","shell.execute_reply":"2024-11-24T17:10:39.369374Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)\n \ntokenizer = WhisperTokenizer.from_pretrained(model_id, language='English', task='transcribe')\n \nprocessor = WhisperProcessor.from_pretrained(model_id, language='English', task='transcribe')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:39.371402Z","iopub.execute_input":"2024-11-24T17:10:39.371743Z","iopub.status.idle":"2024-11-24T17:10:43.130842Z","shell.execute_reply.started":"2024-11-24T17:10:39.371704Z","shell.execute_reply":"2024-11-24T17:10:43.129921Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbae8034db8846bf974814298d782e83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d16cfec65e5f44978b3886b96a619d4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba45730cb5a54cd59861d7fa729fc00c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e556be5520a14bb38d4fc259e711f5fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9209dcacb1d944578daad4ca8c34a22b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a56861627ff34f8e81c10833a87b0186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"975bf3749bc84eeeae88fe1b2636c1bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7767f5676494ccf8a121b9565b8fed6"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def prepare_dataset(batch):\n    audio = batch['audio']\n \n    batch['input_features'] = feature_extractor(audio['array'], sampling_rate=audio['sampling_rate']).input_features[0]\n \n    batch['labels'] = tokenizer(batch['text']).input_ids\n \n    return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:43.131900Z","iopub.execute_input":"2024-11-24T17:10:43.132196Z","iopub.status.idle":"2024-11-24T17:10:43.136830Z","shell.execute_reply.started":"2024-11-24T17:10:43.132169Z","shell.execute_reply":"2024-11-24T17:10:43.135911Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_data = train_data.map(prepare_dataset, num_proc=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:10:43.140234Z","iopub.execute_input":"2024-11-24T17:10:43.140495Z","iopub.status.idle":"2024-11-24T17:11:10.336951Z","shell.execute_reply.started":"2024-11-24T17:10:43.140470Z","shell.execute_reply":"2024-11-24T17:11:10.335845Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/381 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a312714f39a45e1b5d369c2dfb23c19"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"test_data = test_data.map(prepare_dataset, num_proc=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:11:10.338460Z","iopub.execute_input":"2024-11-24T17:11:10.338842Z","iopub.status.idle":"2024-11-24T17:21:01.129547Z","shell.execute_reply.started":"2024-11-24T17:11:10.338788Z","shell.execute_reply":"2024-11-24T17:21:01.128678Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d6ac0b956b54e6c8b1ba5196f829ea1"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"val_data = val_data.map(prepare_dataset, num_proc=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:21:01.131006Z","iopub.execute_input":"2024-11-24T17:21:01.131700Z","iopub.status.idle":"2024-11-24T17:21:36.682018Z","shell.execute_reply.started":"2024-11-24T17:21:01.131658Z","shell.execute_reply":"2024-11-24T17:21:36.681144Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/385 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c43039c428b94ce5bfa248062a70b0b7"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: WhisperProcessor\n    decoder_start_token_id: int\n \n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        input_features = [{'input_features': feature['input_features']} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors='pt')\n \n        label_features = [{'input_ids': feature['labels']} for feature in features]\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors='pt')\n \n        labels = labels_batch['input_ids'].masked_fill(labels_batch.attention_mask.ne(1), -100)\n \n        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n \n        batch['labels'] = labels\n \n        return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:21:36.683377Z","iopub.execute_input":"2024-11-24T17:21:36.683678Z","iopub.status.idle":"2024-11-24T17:21:36.691759Z","shell.execute_reply.started":"2024-11-24T17:21:36.683650Z","shell.execute_reply":"2024-11-24T17:21:36.690811Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"model = WhisperForConditionalGeneration.from_pretrained(model_id)\n \nmodel.generation_config.task = 'transcribe'\n \nmodel.generation_config.forced_decoder_ids = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:21:36.692949Z","iopub.execute_input":"2024-11-24T17:21:36.693218Z","iopub.status.idle":"2024-11-24T17:21:42.029400Z","shell.execute_reply.started":"2024-11-24T17:21:36.693192Z","shell.execute_reply":"2024-11-24T17:21:42.028424Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59ad0ff067dd4fd3a234d86d40ac8b0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faae03cb660847afa121c9e5c5564908"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43fbda24370c4edfac92aa79973ad41c"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n    processor=processor,\n    decoder_start_token_id=model.config.decoder_start_token_id,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:21:42.030566Z","iopub.execute_input":"2024-11-24T17:21:42.030925Z","iopub.status.idle":"2024-11-24T17:21:42.035538Z","shell.execute_reply.started":"2024-11-24T17:21:42.030860Z","shell.execute_reply":"2024-11-24T17:21:42.034612Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"metric = evaluate.load('wer')\n \ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n \n    # replace -100 with the pad_token_id\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n \n    # we do not want to group tokens when computing the metrics\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n \n    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n \n    return {'wer': wer}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:21:42.036647Z","iopub.execute_input":"2024-11-24T17:21:42.036945Z","iopub.status.idle":"2024-11-24T17:21:42.786645Z","shell.execute_reply.started":"2024-11-24T17:21:42.036918Z","shell.execute_reply":"2024-11-24T17:21:42.786009Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb43413e48b84d9c9778ff0e6dcbcc81"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='whisper-small_kabir',\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=4,\n    learning_rate=5e-5,\n    bf16=False,\n    fp16=True,\n    # num_train_epochs=5,\n    max_steps=1000,\n    warmup_steps=100,\n    evaluation_strategy='steps',\n    logging_strategy='steps',\n    save_strategy='steps',\n    save_steps=250,\n    eval_steps=250,\n    logging_steps=25,\n    predict_with_generate=True,\n    generation_max_length=200,\n    load_best_model_at_end=True,\n    metric_for_best_model='wer',\n    greater_is_better=False,\n    dataloader_num_workers=4,\n    lr_scheduler_type='linear',\n    weight_decay = 0.005,\n    seed=42,\n    data_seed=42,\n    gradient_checkpointing=True\n\n)\n\n\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=train_data,\n    eval_dataset=test_data,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T17:31:48.058363Z","iopub.execute_input":"2024-11-24T17:31:48.058741Z","iopub.status.idle":"2024-11-24T22:24:49.290780Z","shell.execute_reply.started":"2024-11-24T17:31:48.058711Z","shell.execute_reply":"2024-11-24T22:24:49.289498Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 4:52:46, Epoch 83/84]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>250</td>\n      <td>0.001100</td>\n      <td>0.313025</td>\n      <td>11.371356</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.000000</td>\n      <td>0.310968</td>\n      <td>10.052961</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.000000</td>\n      <td>0.313813</td>\n      <td>9.982132</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.000000</td>\n      <td>0.314774</td>\n      <td>9.974083</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nYou have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1000, training_loss=0.0241051216457854, metrics={'train_runtime': 17580.5164, 'train_samples_per_second': 1.82, 'train_steps_per_second': 0.057, 'total_flos': 9.16287504556032e+18, 'train_loss': 0.0241051216457854, 'epoch': 83.33333333333333})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"tokenizer.push_to_hub('whisper-small_kabir')\ntrainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T22:28:09.328342Z","iopub.execute_input":"2024-11-24T22:28:09.328724Z","iopub.status.idle":"2024-11-24T22:28:39.488136Z","shell.execute_reply.started":"2024-11-24T22:28:09.328694Z","shell.execute_reply":"2024-11-24T22:28:39.487278Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d932300da334332b3c406a56e6b5d60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1732469508.e6106ab54c49.30.2:   0%|          | 0.00/16.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23e97e60e45d45c1a59efe0fb58786ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64dddcc3f9854ec291e65fcd18eca179"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 5 LFS files:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06c1d728d6f9494ea5dcc507deadb995"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1732469430.e6106ab54c49.30.1:   0%|          | 0.00/6.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8deb4a0748e34079a63b34ebec2544f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1732468904.e6106ab54c49.30.0:   0%|          | 0.00/6.70k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd9430e63fc94769948a51005adbd024"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Kabir259/whisper-small_kabir/commit/a35ee63915f1e7ecb342a95fa5236be9e01fbb15', commit_message='End of training', commit_description='', oid='a35ee63915f1e7ecb342a95fa5236be9e01fbb15', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Kabir259/whisper-small_kabir', endpoint='https://huggingface.co', repo_type='model', repo_id='Kabir259/whisper-small_kabir'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}