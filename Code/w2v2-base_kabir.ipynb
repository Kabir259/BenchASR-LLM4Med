{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":302713,"sourceType":"datasetVersion","datasetId":125828}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Basic Installs & Data PreProcessing","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets evaluate jiwer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport torchaudio\nfrom datasets import Dataset, DatasetDict\nfrom transformers import (\n    Wav2Vec2Processor,\n    Wav2Vec2ForCTC,\n    Trainer,\n    TrainingArguments,\n    Wav2Vec2CTCTokenizer,\n    Wav2Vec2FeatureExtractor,\n)\nimport evaluate\nimport os\nfrom dataclasses import dataclass\nfrom typing import Dict, List, Optional, Union\nimport numpy as np \n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:13:17.272992Z","iopub.execute_input":"2024-11-23T15:13:17.273366Z","iopub.status.idle":"2024-11-23T15:13:37.494531Z","shell.execute_reply.started":"2024-11-23T15:13:17.273325Z","shell.execute_reply":"2024-11-23T15:13:37.493608Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(new_session=False,\n      write_permission=True, \n      token='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', \n      add_to_git_credential=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:13:37.495887Z","iopub.execute_input":"2024-11-23T15:13:37.496671Z","iopub.status.idle":"2024-11-23T15:13:37.735599Z","shell.execute_reply.started":"2024-11-23T15:13:37.496625Z","shell.execute_reply":"2024-11-23T15:13:37.734743Z"}},"outputs":[{"name":"stdout","text":"Token is valid (permission: write).\n\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\nYou might have to re-authenticate when pushing to the Hugging Face Hub.\nRun the following command in your terminal in case you want to set the 'store' credential helper as default.\n\ngit config --global credential.helper store\n\nRead https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\nToken has not been saved to git credential helper.\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"base_path = \"/kaggle/input/medical-speech-transcription-and-intent/Medical Speech, Transcription, and Intent\"\ncsv_file_path = os.path.join(base_path, \"overview-of-recordings.csv\")\nrecordings_path = os.path.join(base_path, \"recordings\")\n\ndf = pd.read_csv(csv_file_path)\n\ndef find_subdirectory_and_path(file_name):\n    for subdirectory in ['test', 'train', 'validate']:\n        file_path = os.path.join(recordings_path, subdirectory, file_name)\n        if os.path.exists(file_path):\n            return subdirectory, file_path\n    return None, None \n\ndf[['subdirectory', 'file_path']] = df['file_name'].apply(\n    lambda file_name: pd.Series(find_subdirectory_and_path(file_name))\n)\ndf = df.drop(['writer_id','speaker_id','file_download','file_name'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T17:17:17.790408Z","iopub.execute_input":"2024-11-23T17:17:17.790799Z","iopub.status.idle":"2024-11-23T17:17:25.086154Z","shell.execute_reply.started":"2024-11-23T17:17:17.790765Z","shell.execute_reply":"2024-11-23T17:17:25.085451Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict, Audio\nimport pandas as pd\n\ndataset = Dataset.from_pandas(df)\n\ntrain_dataset = dataset.filter(lambda x: x['subdirectory'] == 'train')\ntest_dataset = dataset.filter(lambda x: x['subdirectory'] == 'test')\nvalidate_dataset = dataset.filter(lambda x: x['subdirectory'] == 'validate')\n\ndataset_dict = DatasetDict({\n    \"train\": train_dataset,\n    \"test\": test_dataset,\n    \"validate\": validate_dataset\n})\n\nfor split in dataset_dict:\n    dataset_dict[split] = dataset_dict[split].cast_column(\"file_path\", Audio())\n    dataset_dict[split] = dataset_dict[split].rename_column(\"file_path\", \"audio\")\n    dataset_dict[split] = dataset_dict[split].rename_column(\"phrase\", \"text\")\n\n\ndata = dataset_dict.remove_columns([\"subdirectory\",\"prompt\",'audio_clipping', 'audio_clipping:confidence',\n                                    'background_noise_audible', 'background_noise_audible:confidence',\n                                    'overall_quality_of_the_audio', 'quiet_speaker', 'quiet_speaker:confidence'])\n\nprint(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T17:17:25.087861Z","iopub.execute_input":"2024-11-23T17:17:25.088200Z","iopub.status.idle":"2024-11-23T17:17:25.375754Z","shell.execute_reply.started":"2024-11-23T17:17:25.088162Z","shell.execute_reply":"2024-11-23T17:17:25.374904Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bd4ce29a8ee4c3e9c8594674eebf036"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1fa09a11df7426e91ad3168552cc736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/6661 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3518d5a3c54c48e9890960379bfd3ddf"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'audio'],\n        num_rows: 381\n    })\n    test: Dataset({\n        features: ['text', 'audio'],\n        num_rows: 5895\n    })\n    validate: Dataset({\n        features: ['text', 'audio'],\n        num_rows: 385\n    })\n})\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"# Text Cleanup","metadata":{}},{"cell_type":"code","source":"import re\nchars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\ï\\`\\√\\d\\\\n]'\n\ndef remove_special_characters(batch):\n    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n    return batch\n    \ndata = data.map(remove_special_characters)\n\ndef extract_all_chars(batch):\n  all_text = \" \".join(batch[\"text\"])\n  vocab = list(set(all_text))\n  return {\"vocab\": [vocab], \"all_text\": [all_text]}\n\nvocabs = data.map(extract_all_chars, batched=True, \n                  batch_size=-1, \n                  keep_in_memory=True, \n                  remove_columns=data.column_names[\"train\"])\n\nvocab_list = list(set(vocabs[\"train\"][\"vocab\"][0]) | set(vocabs[\"test\"][\"vocab\"][0]))\nvocab_dict = {v: k for k, v in enumerate(sorted(vocab_list))}\n\nvocab_dict[\"|\"] = vocab_dict[\" \"]\ndel vocab_dict[\" \"]\nvocab_dict[\"[UNK]\"] = len(vocab_dict)\nvocab_dict[\"[PAD]\"] = len(vocab_dict)\n\nimport json\n\nwith open('vocab.json', 'w') as vocab_file:\n    json.dump(vocab_dict, vocab_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T17:17:25.376970Z","iopub.execute_input":"2024-11-23T17:17:25.377326Z","iopub.status.idle":"2024-11-23T17:17:26.121164Z","shell.execute_reply.started":"2024-11-23T17:17:25.377286Z","shell.execute_reply":"2024-11-23T17:17:26.120250Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/381 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72719ab4a275441cb64531fb8b123a77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f73643cfd4ad43d3803a88fde983a2d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/385 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff607dc82074e279e0951be36e5221e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/381 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ced08db403f42279a60eee40f2575c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5895 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73b02216551405cb95d571d6e2e3b5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/385 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f15142d907c447c0a71f958df75745b5"}},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"len(vocab_dict) # should be below 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T17:13:50.750245Z","iopub.execute_input":"2024-11-23T17:13:50.750899Z","iopub.status.idle":"2024-11-23T17:13:50.757238Z","shell.execute_reply.started":"2024-11-23T17:13:50.750858Z","shell.execute_reply":"2024-11-23T17:13:50.756468Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"30"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"# Loading","metadata":{}},{"cell_type":"code","source":"from transformers import Wav2Vec2CTCTokenizer\n\ntokenizer = Wav2Vec2CTCTokenizer( # added from_pretrained\n    \"./vocab.json\",\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    word_delimiter_token=\"|\"\n    # return_tensors=\"pt\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:14:52.682479Z","iopub.execute_input":"2024-11-23T15:14:52.683063Z","iopub.status.idle":"2024-11-23T15:14:52.691983Z","shell.execute_reply.started":"2024-11-23T15:14:52.683022Z","shell.execute_reply":"2024-11-23T15:14:52.691016Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from transformers import Wav2Vec2FeatureExtractor\n\nfeature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:14:52.879144Z","iopub.execute_input":"2024-11-23T15:14:52.879763Z","iopub.status.idle":"2024-11-23T15:14:52.883911Z","shell.execute_reply.started":"2024-11-23T15:14:52.879729Z","shell.execute_reply":"2024-11-23T15:14:52.883016Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from transformers import Wav2Vec2Processor\n\nprocessor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:14:53.078163Z","iopub.execute_input":"2024-11-23T15:14:53.078997Z","iopub.status.idle":"2024-11-23T15:14:53.082874Z","shell.execute_reply.started":"2024-11-23T15:14:53.078963Z","shell.execute_reply":"2024-11-23T15:14:53.081939Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def prepare_dataset(batch):\n    audio = batch[\"audio\"]\n    batch = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], text=batch[\"text\"])\n    batch[\"input_length\"] = len(batch[\"input_values\"][0])\n    return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T17:15:17.877420Z","iopub.execute_input":"2024-11-23T17:15:17.877811Z","iopub.status.idle":"2024-11-23T17:15:17.883271Z","shell.execute_reply.started":"2024-11-23T17:15:17.877779Z","shell.execute_reply":"2024-11-23T17:15:17.882406Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"data = data.cast_column(\"audio\", Audio(sampling_rate=16_000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T17:17:34.525110Z","iopub.execute_input":"2024-11-23T17:17:34.525857Z","iopub.status.idle":"2024-11-23T17:17:34.534400Z","shell.execute_reply.started":"2024-11-23T17:17:34.525821Z","shell.execute_reply":"2024-11-23T17:17:34.533695Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"data = data.map(prepare_dataset, remove_columns=data.column_names[\"train\"], num_proc=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional, Union\n\n\n@dataclass\nclass DataCollatorCTCWithPadding:\n    processor: Wav2Vec2Processor\n    padding: Union[bool, str] = True\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need\n        # different padding methods\n        input_features = [{\"input_values\": feature[\"input_values\"][0]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n\n        batch = self.processor.pad(input_features, padding=self.padding, return_tensors=\"pt\")\n\n        labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        batch[\"labels\"] = labels\n\n        return batch\n\ndata_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:16:34.875100Z","iopub.execute_input":"2024-11-23T15:16:34.875401Z","iopub.status.idle":"2024-11-23T15:16:34.883836Z","shell.execute_reply.started":"2024-11-23T15:16:34.875372Z","shell.execute_reply":"2024-11-23T15:16:34.883022Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import evaluate\nimport numpy as np\n\nwer_metric = evaluate.load(\"wer\")\n\ndef compute_metrics(pred):\n    pred_logits = pred.predictions\n    pred_ids = np.argmax(pred_logits, axis=-1)\n\n    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n\n    pred_str = processor.batch_decode(pred_ids)\n    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n\n    wer = float('inf') # init wer with a default value\n\n    try:\n        wer = wer_metric.compute(predictions=pred_str, references=label_str)\n    except Exception as e:\n        print(f\"Error computing WER. Predictions: {pred_str}, References: {label_str}, Error: {e}\")\n\n    return {\"wer\": wer}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:16:34.911150Z","iopub.execute_input":"2024-11-23T15:16:34.911392Z","iopub.status.idle":"2024-11-23T15:16:36.792836Z","shell.execute_reply.started":"2024-11-23T15:16:34.911366Z","shell.execute_reply":"2024-11-23T15:16:36.791902Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12829ef46d4d40d4b73f34ba83c4d8e9"}},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# wandb: 25d0c05384d1f94a41954af5bd655f4014f67ee5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:16:36.793957Z","iopub.execute_input":"2024-11-23T15:16:36.794226Z","iopub.status.idle":"2024-11-23T15:16:36.798299Z","shell.execute_reply.started":"2024-11-23T15:16:36.794202Z","shell.execute_reply":"2024-11-23T15:16:36.797409Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from transformers import AutoModelForCTC, TrainingArguments, Trainer\n\nmodel = AutoModelForCTC.from_pretrained(\n    \"facebook/wav2vec2-base\",\n    ctc_loss_reduction=\"mean\",\n    pad_token_id=processor.tokenizer.pad_token_id,\n)\n\ntraining_args = TrainingArguments(\n    output_dir=\"w2v2-base_kabir\",\n    per_device_train_batch_size=8,  \n    gradient_accumulation_steps=2,  \n    learning_rate=5e-5,  # experiment\n    weight_decay = 0.005, # experiment\n    lr_scheduler_type=\"cosine\",  # experiment\n    warmup_steps=250,  # experiemnt, ~10% of max_steps\n    max_steps=2500,  # experiment\n    gradient_checkpointing=True,\n    fp16=True,\n    group_by_length=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=8,\n    save_steps=500,\n    eval_steps=500,\n    logging_steps=25,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n    remove_unused_columns=False\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=data[\"train\"],\n    eval_dataset=data[\"test\"],\n    tokenizer=processor,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T15:16:36.801016Z","iopub.execute_input":"2024-11-23T15:16:36.801251Z","iopub.status.idle":"2024-11-23T17:05:34.552201Z","shell.execute_reply.started":"2024-11-23T15:16:36.801228Z","shell.execute_reply":"2024-11-23T17:05:34.551358Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a894dcd7e064d71a06bc570a38f8da3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:302: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d401b74c95f4dd092e89d851abbe98f"}},"metadata":{}},{"name":"stderr","text":"Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['lm_head.bias', 'lm_head.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113603988890948, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a65ad4d0e0204445ac0b57531adae163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241123_151658-yr8sme12</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/kabirkumar-iit-delhi/huggingface/runs/yr8sme12' target=\"_blank\">w2v2-base_kabir</a></strong> to <a href='https://wandb.ai/kabirkumar-iit-delhi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/kabirkumar-iit-delhi/huggingface' target=\"_blank\">https://wandb.ai/kabirkumar-iit-delhi/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/kabirkumar-iit-delhi/huggingface/runs/yr8sme12' target=\"_blank\">https://wandb.ai/kabirkumar-iit-delhi/huggingface/runs/yr8sme12</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2500/2500 1:48:05, Epoch 104/105]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.877100</td>\n      <td>2.889694</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.311500</td>\n      <td>0.968696</td>\n      <td>0.412518</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.124800</td>\n      <td>0.942115</td>\n      <td>0.350155</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.065800</td>\n      <td>0.989352</td>\n      <td>0.334847</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.070300</td>\n      <td>0.970529</td>\n      <td>0.328939</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2500, training_loss=1.4510259091377258, metrics={'train_runtime': 6497.7528, 'train_samples_per_second': 6.156, 'train_steps_per_second': 0.385, 'total_flos': 3.0242682553815286e+18, 'train_loss': 1.4510259091377258, 'epoch': 104.16666666666667})"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"markdown","source":"## Push to Hub","metadata":{}},{"cell_type":"code","source":"tokenizer.push_to_hub('w2v2-base_kabir')\ntrainer.push_to_hub()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T17:05:34.553411Z","iopub.execute_input":"2024-11-23T17:05:34.553789Z","iopub.status.idle":"2024-11-23T17:05:40.004010Z","shell.execute_reply.started":"2024-11-23T17:05:34.553743Z","shell.execute_reply":"2024-11-23T17:05:40.003085Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Kabir259/w2v2-base_kabir/commit/322f5c888f864e9bcf92899e10f12c2afca4f0fa', commit_message='End of training', commit_description='', oid='322f5c888f864e9bcf92899e10f12c2afca4f0fa', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Kabir259/w2v2-base_kabir', endpoint='https://huggingface.co', repo_type='model', repo_id='Kabir259/w2v2-base_kabir'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"## Locally ","metadata":{}},{"cell_type":"code","source":"# !zip -r w2v2-base_1.0.zip /kaggle/working/w2v2-base_kabir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T18:14:31.744546Z","iopub.execute_input":"2024-11-23T18:14:31.744876Z","iopub.status.idle":"2024-11-23T18:14:32.750858Z","shell.execute_reply.started":"2024-11-23T18:14:31.744844Z","shell.execute_reply":"2024-11-23T18:14:32.749743Z"}},"outputs":[{"name":"stdout","text":"\tzip warning: name not matched: /kaggle/working/w2v2-base_kabir\n\nzip error: Nothing to do! (try: zip -r w2v2-base_1.0.zip . -i /kaggle/working/w2v2-base_kabir)\n","output_type":"stream"}],"execution_count":1}]}